dados_imo |> filter(is.na(vaga)) |> select(c(vaga, tipo)) |> group_by(c(tipo,vaga))
dados_imo |> filter(is.na(vaga)) |> select(c(vaga, tipo)) |> group_by(c(vaga)
)
dados_imo |> filter(is.na(vaga)) |> select(c(vaga, tipo)) |> group_by(tipo)
dados_imo |> filter(is.na(vaga)) |> select(c(vaga, tipo)) |> group_by(tipo) |> count()
dados_imo |> group_by(tipo) |> count()
dados_imo |> filter(is.na(vaga)) |> select(c(vaga, tipo)) |> group_by(tipo, vaga) |> count()
dados_imo |> filter(!is.na(vaga)) |> select(c(vaga, tipo))
dados_imo |> filter(!is.na(vaga) & tipo == "flat") |> select(c(vaga, tipo))
dados_imo |> filter(!is.na(vaga) & tipo == "flat") |> select(c(vaga, tipo)) |> filter(unique(vaga))
dados_imo |> filter(!is.na(vaga) & tipo == "flat") |> select(c(vaga, tipo)) |> filter(vaga != 1)
library(dplyr)
library(tibble)
library(readr)
library(ggplot2)
library(purrr)
library(visdat)
dados_imo <- get(load("/home/gabriel/Downloads/dados.RData")) |> as_tibble()
dados_imo |> head()
vis_dat(dados_imo)
vis_dat(dados_imo)
vis_miss(dados_imo)
dados_imo <- dados_imo |> select(-c(iptu, condominio))
dados_imo <- dados_imo |> select(-c(iptu, condominio))
dados_imo |>
group_by(tipo) |>
count() |>
mutate(per = n / dados_imo |> ncol)
dados_imo |>
group_by(tipo) |>
count() |>
mutate(per = n / dados_imo |> ncol(
))
dados_imo |>
group_by(tipo) |>
count() |>
mutate(per = n / dados_imo |> ncol()
)
dados_imo |>
group_by(tipo) |>
count() |>
mutate(per = n / dados_imo |> nrows() * 100
)
dados_imo |>
group_by(tipo) |>
count() |>
mutate(per = (n / dados_imo |> nrows()) * 100
)
dados_imo |>
group_by(tipo) |>
count() |>
mutate(per = n / dados_imo |> nrows()
)
dados_imo |>
group_by(tipo) |>
count() |>
mutate(per = n / dados_imo |> nrow() )
dados_imo |>
group_by(tipo) |>
count() |>
mutate(per = n / dados_imo |> nrow() * 100)
dados_imo |>
group_by(tipo) |>
count() |>
mutate(per = n / dados_imo |> nrow() * 100) |>
arrange(per)
dados_imo |>
group_by(tipo) |>
count() |>
mutate(per = n / dados_imo |> nrow() * 100) |>
arrange(per |> desc())
help("mutate")
help(imutate)
??imutate
imo_tipos
imo_tipos <- dados_imo |>
group_by(tipo) |>
count() |>
mutate(per = n / dados_imo |> nrow() * 100) |>
arrange(per |> desc())
imo_tipos
imo_tipos |> ggplot(aes(x=tipo, y=per))
imo_tipos |> ggplot(aes(x=tipo, y=per)) |>
geom_bar()
imo_tipos |> ggplot(aes(x=tipo, y=per)) +
geom_bar()
imo_tipos |> ggplot(aes(x=tipo, y=per)) +
geom_bar(stat = "identity")
dados_imo |> group_by(tipo) |> count()
imo_tipos
imo_tipos |> ggplot(aes(x=tipo, y=per)) +
geom_bar(stat = "identity")
imo_tipos |> ggplot(aes(x=as.factor(tipo), y=per)) +
geom_bar(stat = "identity")
imo_tipos |> ggplot(aes(x = as.factor(tipo), y = per, fill = tipo)) +
geom_bar(stat = "identity")
imo_tipos
imo_tipos |> ggplot(aes(x = as.factor(tipo), y = per, color = tipo)) +
geom_bar(stat = "identity")
imo_tipos |> ggplot(aes(x = as.factor(tipo), y = per, fill = tipo)) +
geom_bar(stat = "identity")
imo_tipos |> ggplot(aes(x = as.factor(tipo), y = per, color = tipo)) +
geom_bar(stat = "identity")
imo_tipos |> ggplot(aes(x = as.factor(tipo), y = per, color = tipo)) +
geom_bar(stat = "identity") +
theme(axis.title.x = '')
imo_tipos |> ggplot(aes(x = as.factor(tipo), y = per, color = tipo)) +
geom_bar(stat = "identity") +
theme(axis.ticks = element_blank())
imo_tipos |> ggplot(aes(x = as.factor(tipo), y = per, color = tipo)) +
geom_bar(stat = "identity") +
theme(axis.ticks.x = element_blank())
imo_tipos |> ggplot(aes(x = as.factor(tipo), y = per, color = tipo)) +
geom_bar(stat = "identity") +
theme(axis.text.x = element_blank(),
axis.ticks = element_blank())
imo_tipos |> ggplot(aes(x = as.factor(tipo), y = per, color = tipo)) +
geom_bar(stat = "identity") +
theme(axis.text.x = element_blank(),
axis.ticks = element_blank(),
axis.ticks.x = 'a')
imo_tipos |> ggplot(aes(x = as.factor(tipo), y = per, color = tipo)) +
geom_bar(stat = "identity") +
theme(axis.text.x = element_blank(),
axis.ticks = element_blank())
library(rsample)
imo_split <- initial_split(data = dados_imo, prop = 4/5)
imo_split
train_data <- training(imo_split)
test_data <- testing(imo_split)
train_data
test_data
write.csv("/home/gabriel/Documents/imoveis2/dados_imo.csv", index=FALSE)
help("write.csv")
write.csv("/home/gabriel/Documents/imoveis2/dados_imo.csv")
write.csv(dados_imo"/home/gabriel/Documents/imoveis2/dados_imo.csv")
dados_imo <- get(load("/home/gabriel/Downloads/dados.RData")) |> as_tibble()
write.csv(dados_imo,"/home/gabriel/Documents/imoveis2/dados_imo.csv")
?dbinom
pbinom(6, 20, 1/2)
qnorm(0.14)
qnorm(0.0228)
qnorm(1-0.0228)
qnorm(1-0.0228)*8
(qnorm(1-0.0228)*8) ** 2
sqrt(256)
qnorm(0.1587)
qnorm(0.1587) + 7
prnom((125 - 25*6)/50)
pnorm((125 - 25*6)/50)
1-0.308
9.5/2
4.75^2
3.14*22.5625*15.5
(4*3.14*10^3)/3
library(dplyr)
banco <- tibble(Unit = seq(9),
x = c(13, 7, 11, 12, 4, 3, 11, 3, 5),
y = c(10, 7, 13, 17, 8, 1, 15, 7, 4)
)
banco
banco <- tibble(Unit = 1:9,
x = c(13, 7, 11, 12, 4, 3, 11, 3, 5),
y = c(10, 7, 13, 17, 8, 1, 15, 7, 4)
)
banco
banco$x |> sum()
banco$y |> sum()
82/69
(banco$x - 69) * (banco$y - 82)
(banco$x - 69) * (banco$y - 82)
length(banco$x)
((banco$x - 69) * (banco$y - 82))/(8*sd(banco$x * banco$y))
(sum((banco$x - 69) * (banco$y - 82)))/(8*sd(banco$x * banco$y))
ppois(8, lambda = 0,5)
?ppois(8, lambda = 0,5)
dpois(8, 0.5)
dpois(7, 0.5)
sapply(1:8, FUN = \(x) dpois(x, 0.5))
sum(sapply(1:8, FUN = \(x) dpois(x, 0.5)))
1- sum(sapply(1:8, FUN = \(x) dpois(x, 0.5)))
punif(0.92)
1 - punif(0.92)
punif(0.92, max = 2)
0.9^2
0.9^2 -1
1 - pnorm((6.296 - 3)/(sqrt(3)*3/3))
sqrt(256)
1 - 0.49
qnorm(0.01)
0.49 -1
0.49*0.51
qnorm(0.9)
qnorm(0.99)
3*6.296
pgamma(3*6.296)
?pgamma(3*6.296)
pgamma(3*6.296, shape = 3, rate = 1/3)
1 -pgamma(3*6.296, shape = 3, rate = 1/3)
1- 0.9^3
1 - (pbinom(4, 7, 0.271) - dbinom(4, 7, 0.271))
1 - pbinom(3, 7, 0.271)
qnorm(0.0228)
qnorm(0.1587)
qnorm(1 - 0.0228)
(8 * 0.999)^2
8 ^2
(1.999*16*8 + 5*64)/64 + 2
(125 - 25*6)/50
pnorm((125 - 25*6)/50)
1 - pgeom(4, 0.3)
10/1.08
pbinom(6, 10)
pbinom(6, 10, 0.5)
pbinom(6, 20, 0.5)
qnorm(0.05/2)
(23 - 18)/(16/5)
qnorm(0.01/2)
0.95/2
0.05/2
18 + 2.58*16/5
18-2.58*16/5
qnorm(0.01)
18 - 2.32*16/5
18 + 2.32*16/5
qnorm(1-0.01)
1-0.49
qnorm(0.01)
2*0.49
sqrt(0.49*0.51)
sqrt(0.49*0.51*2)
sqrt(0.49*0.51*2)*2.32
1-0.98
1.64016*0.98
1.64016/0.02
(1.64016/0.02)^2
(1.64016/0.02)^2*2
getwd
ls
ls()
qbinom(0.95, 15, 0.1)
qbinom(0.95, 15, 0.1)
1 - pbinom(4, 15, 0.1)
1 - pbinom(5, 15, 0.1)
1 - pbinom(3, 15, 0.1)
1 - pbinom(2, 15, 0.1)
1 - pbinom(6, 15, 0.1)
1 - pbinom(4, 15, 0.1)
(10^4 + 121)/110
144/12
121-40
5/4
89/20
121/11
(10^4 + 121)/110
install.packages("modeldata")
?enquos
step_nadrop <- function(
recipe,
...,
role = NA,
trained = NA,
skip = FALSE,
id = rand_id("dropna")
) {
add_step(
recipe,
step_dropna_new(
terms = enquos(...),
trained = trained,
skip = skip,
id = id
)
)
}
# receita
dados_rec <- dados  |>
recipe(Ponto_Medio ~., data = dados) |>
step_arrange(Data) |>
step_lag(starts_with(c("M", "Fecha")), lag = c(1, 9, 22), role = "lag") |>
step_arrange(desc(Data))
# random forest com a engine ranger
rand_model <- rand_forest() |>
set_engine("ranger", num.trees = tune(), mtry = tune(),
max.depth = tune(), alpha = tune(), importance = tune(),
min.bucket = tune(), min.node.size = tune()) |>
set_mode("regression")
dados_final <- dados_rec |> prep() |> bake(new_data = dados) |> drop_na()
# criando workflow
rand_wf <- workflow() |>
add_recipe(dados_rec) |>
add_model(rand_model)
# ----------------
# ********************************************************
# ********************************************************
#             Modelos Finais
# ********************************************************
#             Modelos Finais
#*********************************************************
# ********************************************************
#             Modelos Finais
#*********************************************************
# **********************************************
step_nadrop()
library(tidyverse)
library(tidymodels)
library(randomForest)
library(readxl)
library(visdat)
step_nadrop <- function(
recipe,
...,
role = NA,
trained = NA,
skip = FALSE,
id = rand_id("dropna")
) {
add_step(
recipe,
step_dropna_new(
terms = enquos(...),
trained = trained,
skip = skip,
id = id
)
)
}
step_nadrop()
step_dropna <- function(
recipe,
...,
role = NA,
trained = NA,
skip = FALSE,
id = rand_id("dropna")
) {
add_step(
recipe,
step_dropna_new(
terms = enquos(...),
trained = trained,
skip = skip,
id = id
)
)
}
?enquos()
?recipes_eval_select()
?Reduce
Reduce('+', x)
Reduce('+', c(1, 2,3))
euler <- function(f, x0, y0, xf, h) {
steps <- seq(x0, xf, h)
initial <- c(x = x0, y = y0)
result <- Reduce(function(prev, x) {
y_prev <- prev$y
x_prev <- prev$x
y_next <- y_prev + h * f(x_prev, y_prev)
x_next <- x
cbind(prev, data.frame(x = x_next, y = y_next))
}, steps[-1], init = initial, accumulate = TRUE)
return(result)
}
euler(\(x, y) x^3 - y, 0, 2, 1, 0.25)
euler <- function(f, x0, y0, xf, h) {
steps <- seq(x0, xf, h)
initial <- list(x = x0, y = y0)
result <- Reduce(function(prev, x) {
y_prev <- prev$y
x_prev <- prev$x
y_next <- y_prev + h * f(x_prev, y_prev)
x_next <- x
cbind(prev, data.frame(x = x_next, y = y_next))
}, steps[-1], init = initial, accumulate = TRUE)
return(result)
}
euler(\(x, y) x^3 - y, 0, 2, 1, 0.25)
euler <- function(f, x0, y0, xf, h) {
x <- seq(x0, xf, h)
y <- numeric(length(x))
y[1] <- y0
for (i in 2:length(x)) {
y[i] <- y[i - 1] + h * f(x[i - 1], y[i - 1])
}
tibble(x = x, y = y)
}
euler(\(x, y) x^3 - y, 0, 2, 1, 0.25)
library(dplyr)
euler(\(x, y) x^3 - y, 0, 2, 1, 0.25)
MetodoEuler <- function(f, x0, y0, xf, h) {
x <- seq(x0, xf, h)
y <- numeric(length(x))
y[1] <- y0
for (i in 2:length(x)) {
y[i] <- y[i - 1] + h * f(x[i - 1], y[i - 1])
}
tibble(x = x, y = y)
}
1- qbinom(6, 10, 1/) - dbinom(6, 10, 1/2)
1- qbinom(6, 10, 1/2) - dbinom(6, 10, 1/2)
1- pbinom(6, 10, 1/2) - dbinom(6, 10, 1/2)
pbinom(6, 10, 1/2)
dbinom(6, 10, 1/2)
pbinom(5, 10, 1/2)
1- pbinom(5, 10, 1/2)
setwd("/home/gabriel/Documents/model_mercado_financeiro")
library(tidyverse)
library(tidymodels)
library(randomForest)
library(readxl)
library(visdat)
tidymodels_prefer()
dados <- read_excel("./WDOLFUT-DIARIO-02_01_2018_a_03-05-2023.xlsx",
col_types = c("date", "numeric", "numeric","numeric", "numeric")
)
dados <- dados |> mutate(Ponto_Medio = round((Maxima + Minima)/ 2, 2))
# step para remover valores ausentes
# step_dropna <- function(
#     recipe,
#     ...,
#     role = NA,
#     trained = NA,
#     skip = FALSE,
#     id = rand_id("dropna")
#     ) {
#
#   add_step(
#     recipe,
#     step_dropna_new(
#       terms = enquos(...),
#       trained = trained,
#       skip = skip,
#       id = id
#     )
#   )
# }
#
# step_dropna_new <- function(terms, role = "drop_na", trained, skip, id) {
#   step(
#     subclass = "dropna",
#     role = role,
#     terms = terms,
#     trained,
#     skip = skip,
#     id = id
#   )
# }
#
# prep.step_dropna <- function(x, training, info = NULL, ...) {
#   col_names <- recipes_eval_select(x$terms, training, info)
#
#   step_dropna_new(
#     terms = terms$x,
#     trained = TRUE,
#     role = x$role,
#     skip = x$skip,
#     id = x$id
#   )
# }
#
# bake.step_dropna <- function(object, new_data, ...) {
#   new_data <- new_data |> drop_na()
#   new_data
# }
# receita
dados_rec <- dados  |>
recipe(Ponto_Medio ~., data = dados) |>
step_arrange(Data) |>
step_lag(starts_with(c("M", "Fecha")), lag = c(1, 9, 22), role = "lag") |>
step_arrange(desc(Data)) |>
step_naomit()
# random forest com a engine ranger
rand_model <- rand_forest(min_n = tune(), trees = tune(), mtry = tune()) |>
set_engine("ranger", alpha = tune()) |>
set_mode("regression")
dados_final <- dados_rec |> prep() |> bake(new_data = dados) |> drop_na()
rand_params <- rand_model |>
extract_parameter_set_dials() |>
update(trees = trees(c(50, 1000)),
mtry = mtry(c(1, 5)),
alpha = mixture(),
min_n = min_n(c(2, 100))
)
# criando workflow
rand_wf <- workflow() |>
add_recipe(dados_rec) |>
add_model(rand_model)
# banco de teste e treinamento
amostra <- sample(2, nrow(dados_final), replace = TRUE, prob = c(0.7, 0.3))
conjunto_treinamento <- dados_final[amostra == 1, ]
conjunto_teste <- dados_final[amostra == 2, ]
cv <- vfold_cv(data = conjunto_treinamento, v = 20)
tunagem <-
tune_grid(
rand_wf,
resamples = cv,
grid = 50L,
metrics = metric_set(rsq, rmse),
control = control_grid(save_pred = TRUE, verbose = TRUE, allow_par = FALSE),
param_info = rand_params
)
tunagem |> show_best()
tunagem |> show_best(metric = "rsq")
tunagem |> show_best(metric = "rmse")
tunagem |> show_best(metric = "rsq")
tunagem |> show_best(metric = "rsq", n = 10)
tunagem |> show_best(metric = "rsq", n = 50)
print(n = 20)
`print(n=10)`
tunagem |> show_best(metric = "rsq", n = 50)
tunagem |> show_best(metric = "rsq", n = 50) |> View()
tunagem |> show_best(metric = "rmse", n = 50) |> View()
